{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-31T19:33:56.466959Z",
     "start_time": "2024-10-31T19:33:56.101757Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:34:05.880994Z",
     "start_time": "2024-10-31T19:33:56.466959Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = '.\\Solutions\\Run5\\GPT3.5\\ResponseList_gpt-3.5-turbo_no_order.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "total_token_length = sum(sum(eval(cell)) for cell in df['Token length of Prompts'] if pd.notna(cell))\n",
    "total_iteration_time = sum(sum(eval(cell)) for cell in df['Individual iteration time'] if pd.notna(cell))\n",
    "\n",
    "total_ques = 2426\n",
    "print('Moddel 3.5:')\n",
    "print(\"Total Prompt Token Length:\", total_token_length)\n",
    "print(\"Total Iteration Time:\", total_iteration_time)\n",
    "\n",
    "print(\"Avg Prompt Token Length:\", total_token_length/total_ques)\n",
    "print(\"Avg Iteration Time:\", total_iteration_time/total_ques)\n",
    "\n",
    "#For response token we need to use tiktoken and compute the lengths using the python script"
   ],
   "id": "1647b722e52d2220",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moddel 3.5:\n",
      "Total Prompt Token Length: 16643141\n",
      "Total Iteration Time: 41267.06708598137\n",
      "Avg Prompt Token Length: 6860.321929101401\n",
      "Avg Iteration Time: 17.01033268177303\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:34:15.116428Z",
     "start_time": "2024-10-31T19:34:05.880994Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = '.\\Solutions\\Run5\\GPT4omini\\ResponseList_gpt-4o-mini_no_order.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "total_token_length = sum(sum(eval(cell)) for cell in df['Token length of Prompts'] if pd.notna(cell))\n",
    "total_iteration_time = sum(sum(eval(cell)) for cell in df['Individual iteration time'] if pd.notna(cell))\n",
    "\n",
    "total_ques = 2426\n",
    "print('Moddel 4omini:')\n",
    "print(\"Total Prompt Token Length:\", total_token_length)\n",
    "print(\"Total Iteration Time:\", total_iteration_time)\n",
    "\n",
    "print(\"Avg Prompt Token Length:\", total_token_length/total_ques)\n",
    "print(\"Avg Iteration Time:\", total_iteration_time/total_ques)\n",
    "\n",
    "#For response token we need to use tiktoken and compute the lengths using the python script"
   ],
   "id": "9ff00ce8618d2aa0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moddel 4omini:\n",
      "Total Prompt Token Length: 10151542\n",
      "Total Iteration Time: 25228.966774463654\n",
      "Avg Prompt Token Length: 4184.477328936521\n",
      "Avg Iteration Time: 10.399409222779742\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:34:23.284604Z",
     "start_time": "2024-10-31T19:34:15.116428Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = '.\\Solutions\\Run5\\GPT4o\\ResponseList_gpt-4o_no_order.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "total_token_length = sum(sum(eval(cell)) for cell in df['Token length of Prompts'] if pd.notna(cell))\n",
    "total_iteration_time = sum(sum(eval(cell)) for cell in df['Individual iteration time'] if pd.notna(cell))\n",
    "\n",
    "total_ques = 2426\n",
    "print('Moddel 4o:')\n",
    "print(\"Total Prompt Token Length:\", total_token_length)\n",
    "print(\"Total Iteration Time:\", total_iteration_time)\n",
    "\n",
    "print(\"Avg Prompt Token Length:\", total_token_length/total_ques)\n",
    "print(\"Avg Iteration Time:\", total_iteration_time/total_ques)\n",
    "\n",
    "#For response token we need to use tiktoken and compute the lengths using the python script"
   ],
   "id": "d1de123a19c4283d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moddel 4o:\n",
      "Total Prompt Token Length: 7654571\n",
      "Total Iteration Time: 23287.42594218254\n",
      "Avg Prompt Token Length: 3155.2230008244023\n",
      "Avg Iteration Time: 9.599103850858425\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-31T19:36:04.540933Z",
     "start_time": "2024-10-31T19:36:04.122511Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = '.\\Solutions\\o1mini\\ResponseList_o1-mini-no_order.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "total_token_length = sum(sum(eval(cell)) for cell in df['Token length of Prompts'] if pd.notna(cell))\n",
    "total_iteration_time = sum(sum(eval(cell)) for cell in df['Individual iteration time'] if pd.notna(cell))\n",
    "\n",
    "total_ques = 2426\n",
    "print('Moddel o1:')\n",
    "print(\"Total Prompt Token Length:\", total_token_length)\n",
    "print(\"Total Iteration Time:\", total_iteration_time)\n",
    "\n",
    "print(\"Avg Prompt Token Length:\", total_token_length/total_ques)\n",
    "print(\"Avg Iteration Time:\", total_iteration_time/total_ques)\n",
    "\n",
    "#For response token we need to use tiktoken and compute the lengths using the python script"
   ],
   "id": "92fc00ef8c26e38e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moddel o1:\n",
      "Total Prompt Token Length: 3437062\n",
      "Total Iteration Time: 61367.99367928505\n",
      "Avg Prompt Token Length: 1416.7609233305852\n",
      "Avg Iteration Time: 25.295957823283203\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "92287cadf37f19f8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
